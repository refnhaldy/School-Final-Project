{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Installing pyspark\n",
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "0Iam3wZ-Ze1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "HoZOV0VE5AIX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98610fad-bcb0-44ed-da5e-43533e0ba680"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating Model**\n",
        "\n",
        "Heart data https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction"
      ],
      "metadata": {
        "id": "fUVKzf-pZRYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import library\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder.appName(\"HeartDiseasePrediction\").getOrCreate()\n",
        "\n",
        "# Load the data\n",
        "data = spark.read.csv(\"drive/MyDrive/Data For Colab/heart.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Drop missing values\n",
        "data = data.dropna()\n",
        "data.show(5)"
      ],
      "metadata": {
        "id": "YQR-YEhhZyEJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0201138-01f4-4f20-c6d5-095ef6fb4fe1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+-------------+---------+-----------+---------+----------+-----+--------------+-------+--------+------------+\n",
            "|Age|Sex|ChestPainType|RestingBP|Cholesterol|FastingBS|RestingECG|MaxHR|ExerciseAngina|Oldpeak|ST_Slope|HeartDisease|\n",
            "+---+---+-------------+---------+-----------+---------+----------+-----+--------------+-------+--------+------------+\n",
            "| 40|  M|          ATA|      140|        289|        0|    Normal|  172|             N|    0.0|      Up|           0|\n",
            "| 49|  F|          NAP|      160|        180|        0|    Normal|  156|             N|    1.0|    Flat|           1|\n",
            "| 37|  M|          ATA|      130|        283|        0|        ST|   98|             N|    0.0|      Up|           0|\n",
            "| 48|  F|          ASY|      138|        214|        0|    Normal|  108|             Y|    1.5|    Flat|           1|\n",
            "| 54|  M|          NAP|      150|        195|        0|    Normal|  122|             N|    0.0|      Up|           0|\n",
            "+---+---+-------------+---------+-----------+---------+----------+-----+--------------+-------+--------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert categorical columns to numeric\n",
        "indexers = [StringIndexer(inputCol=c, outputCol=c+\"_index\") for c, t in data.dtypes if t.startswith(\"string\") ]\n",
        "\n",
        "# One-hot encode indexed columns\n",
        "encoders = [OneHotEncoder(inputCol=indexer.getOutputCol(), outputCol=indexer.getOutputCol() + \"_ohe\") for indexer in indexers]\n",
        "\n",
        "# Select columns features to assemble\n",
        "selected_cols = [\"Age\", \"Sex_index\", \"RestingBP\", \"Cholesterol\", \"MaxHR\", \"Oldpeak\"]\n",
        "encoded_cols = [encoder.getOutputCol() for encoder in encoders]\n",
        "\n",
        "# Assemble features into a single vector\n",
        "assembler = VectorAssembler(inputCols=selected_cols + encoded_cols, outputCol=\"features\")\n",
        "\n",
        "# Create the pipeline\n",
        "pipeline = Pipeline(stages=indexers + encoders + [assembler])\n",
        "\n",
        "data = pipeline.fit(data).transform(data)\n",
        "data.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClRRy4EmuOkc",
        "outputId": "20fcab1e-acac-4a0a-94ac-ccb083384c10"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+-------------+---------+-----------+---------+----------+-----+--------------+-------+--------+------------+---------+-------------------+----------------+--------------------+--------------+-------------+-----------------------+--------------------+------------------------+------------------+--------------------+\n",
            "|Age|Sex|ChestPainType|RestingBP|Cholesterol|FastingBS|RestingECG|MaxHR|ExerciseAngina|Oldpeak|ST_Slope|HeartDisease|Sex_index|ChestPainType_index|RestingECG_index|ExerciseAngina_index|ST_Slope_index|Sex_index_ohe|ChestPainType_index_ohe|RestingECG_index_ohe|ExerciseAngina_index_ohe|ST_Slope_index_ohe|            features|\n",
            "+---+---+-------------+---------+-----------+---------+----------+-----+--------------+-------+--------+------------+---------+-------------------+----------------+--------------------+--------------+-------------+-----------------------+--------------------+------------------------+------------------+--------------------+\n",
            "| 40|  M|          ATA|      140|        289|        0|    Normal|  172|             N|    0.0|      Up|           0|      0.0|                2.0|             0.0|                 0.0|           1.0|(1,[0],[1.0])|          (3,[2],[1.0])|       (2,[0],[1.0])|           (1,[0],[1.0])|     (2,[1],[1.0])|[40.0,0.0,140.0,2...|\n",
            "| 49|  F|          NAP|      160|        180|        0|    Normal|  156|             N|    1.0|    Flat|           1|      1.0|                1.0|             0.0|                 0.0|           0.0|    (1,[],[])|          (3,[1],[1.0])|       (2,[0],[1.0])|           (1,[0],[1.0])|     (2,[0],[1.0])|[49.0,1.0,160.0,1...|\n",
            "| 37|  M|          ATA|      130|        283|        0|        ST|   98|             N|    0.0|      Up|           0|      0.0|                2.0|             2.0|                 0.0|           1.0|(1,[0],[1.0])|          (3,[2],[1.0])|           (2,[],[])|           (1,[0],[1.0])|     (2,[1],[1.0])|(15,[0,2,3,4,6,9,...|\n",
            "| 48|  F|          ASY|      138|        214|        0|    Normal|  108|             Y|    1.5|    Flat|           1|      1.0|                0.0|             0.0|                 1.0|           0.0|    (1,[],[])|          (3,[0],[1.0])|       (2,[0],[1.0])|               (1,[],[])|     (2,[0],[1.0])|[48.0,1.0,138.0,2...|\n",
            "| 54|  M|          NAP|      150|        195|        0|    Normal|  122|             N|    0.0|      Up|           0|      0.0|                1.0|             0.0|                 0.0|           1.0|(1,[0],[1.0])|          (3,[1],[1.0])|       (2,[0],[1.0])|           (1,[0],[1.0])|     (2,[1],[1.0])|[54.0,0.0,150.0,1...|\n",
            "+---+---+-------------+---------+-----------+---------+----------+-----+--------------+-------+--------+------------+---------+-------------------+----------------+--------------------+--------------+-------------+-----------------------+--------------------+------------------------+------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***String indexer***\n",
        "\n",
        "is used to convert categorical string variables to numerical variables. The output of a string indexer is a numerical representation of a categorical variable, but it should not be interpreted as an actual numerical value. The numbers assigned to each category are simply used as a unique identifier for each category, and have no inherent meaning or relation to each other.\n",
        "\n",
        "For example, we have two categories on sex \"M\", \"F\", first category encountered in the data will be assigned the value 0, the second category will be assigned the value 1, and so on. The number assigned to a category does not indicate any inherent property or relation between the categories, it's just a way of identifying them.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "***One-hot encoder***\n",
        "\n",
        "The important thing is the one-hot encoding process, it takes the output of the indexer and creates a binary vector representation of the categorical variable. The vector has a length equal to the number of possible categories and each element of the vector corresponds to a specific category. The value of the element is set to 1 if the category is present in the original data, and 0 otherwise, regardless of the indexing order."
      ],
      "metadata": {
        "id": "ODI1CPo4LdAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import count\n",
        "# Selecting and renaming column\n",
        "data = data.select(\"features\",\"HeartDisease\")\n",
        "data = data.withColumnRenamed(\"HeartDisease\",\"label\")\n",
        "data.show(5)\n",
        "\n",
        "# See the scale of the data\n",
        "data.groupBy(\"label\").agg(count(\"*\").alias(\"count\")).show()\n",
        "print(\"The data should be roughly around 50:50 or at the same scale\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KahlTRaC0wdA",
        "outputId": "4c67074b-2f04-4471-a855-942b483fc4da"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+\n",
            "|            features|label|\n",
            "+--------------------+-----+\n",
            "|[40.0,0.0,140.0,2...|    0|\n",
            "|[49.0,1.0,160.0,1...|    1|\n",
            "|(15,[0,2,3,4,6,9,...|    0|\n",
            "|[48.0,1.0,138.0,2...|    1|\n",
            "|[54.0,0.0,150.0,1...|    0|\n",
            "+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n",
            "+-----+-----+\n",
            "|label|count|\n",
            "+-----+-----+\n",
            "|    1|  508|\n",
            "|    0|  410|\n",
            "+-----+-----+\n",
            "\n",
            "The data should be roughly around 50:50 or at the same scale\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Random Forest Classifier**\n",
        "\n",
        "This method uses the feature importance measure provided by the Random Forest algorithm, so you don't have to use any other feature selection techniques."
      ],
      "metadata": {
        "id": "2Mcz690n_kS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "# Split the data into training and test sets\n",
        "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
        "\n",
        "# Random Forest Classifier\n",
        "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
        "\n",
        "# Train the model\n",
        "model = rf.fit(trainingData)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = model.transform(testData)\n",
        "\n",
        "# create a BinaryClassificationEvaluator object\n",
        "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\")\n",
        "\n",
        "# calculate the evaluation metrics\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "# print prediction and evaluation metrics\n",
        "predictions.show()\n",
        "print(\"Accuracy: \", accuracy)"
      ],
      "metadata": {
        "id": "hvtjb1sW_iea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b88b41fb-cb73-4fd7-a9af-c99f440d8cc1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+--------------------+--------------------+----------+\n",
            "|            features|label|       rawPrediction|         probability|prediction|\n",
            "+--------------------+-----+--------------------+--------------------+----------+\n",
            "|(15,[0,1,2,3,4,5,...|    1|[3.83547879593311...|[0.19177393979665...|       1.0|\n",
            "|(15,[0,1,2,3,4,5,...|    1|[4.84949396026114...|[0.24247469801305...|       1.0|\n",
            "|(15,[0,1,2,3,4,5,...|    1|[5.17130091270719...|[0.25856504563535...|       1.0|\n",
            "|(15,[0,1,2,3,4,5,...|    0|[10.8611386483128...|[0.54305693241564...|       0.0|\n",
            "|(15,[0,1,2,3,4,7,...|    0|[16.7573178103634...|[0.83786589051817...|       0.0|\n",
            "|(15,[0,1,2,3,4,8,...|    0|[18.6298105856310...|[0.93149052928155...|       0.0|\n",
            "|(15,[0,1,2,3,4,8,...|    0|[18.7553024772519...|[0.93776512386259...|       0.0|\n",
            "|(15,[0,1,2,3,4,8,...|    0|[18.7178460312589...|[0.93589230156294...|       0.0|\n",
            "|(15,[0,1,2,3,4,9,...|    0|[19.4730238823709...|[0.97365119411854...|       0.0|\n",
            "|(15,[0,1,2,3,4,10...|    0|[17.2977685627926...|[0.86488842813963...|       0.0|\n",
            "|(15,[0,1,2,4,7,10...|    1|[4.37390454455133...|[0.21869522722756...|       1.0|\n",
            "|(15,[0,2,3,4,5,6,...|    1|[1.74169590739928...|[0.08708479536996...|       1.0|\n",
            "|(15,[0,2,3,4,5,6,...|    1|[1.17257462737317...|[0.05862873136865...|       1.0|\n",
            "|(15,[0,2,3,4,5,6,...|    1|[2.25666139535486...|[0.11283306976774...|       1.0|\n",
            "|(15,[0,2,3,4,5,6,...|    1|[2.99516812962150...|[0.14975840648107...|       1.0|\n",
            "|(15,[0,2,3,4,5,6,...|    1|[1.17257462737317...|[0.05862873136865...|       1.0|\n",
            "|(15,[0,2,3,4,5,6,...|    1|[1.69440122246850...|[0.08472006112342...|       1.0|\n",
            "|(15,[0,2,3,4,5,6,...|    0|[1.70110583979930...|[0.08505529198996...|       1.0|\n",
            "|(15,[0,2,3,4,5,6,...|    1|[2.50099407495646...|[0.12504970374782...|       1.0|\n",
            "|(15,[0,2,3,4,5,6,...|    1|[2.17234240610175...|[0.10861712030508...|       1.0|\n",
            "+--------------------+-----+--------------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Accuracy:  0.9246243218589479\n"
          ]
        }
      ]
    }
  ]
}